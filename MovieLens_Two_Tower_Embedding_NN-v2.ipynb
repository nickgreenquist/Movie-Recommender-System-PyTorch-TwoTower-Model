{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oH1_445JoNNz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if torch will use Apple Silicon GPU\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens_data_dir = \"ml-32m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbUl4oLiocXu"
   },
   "outputs": [],
   "source": [
    "num_ratings_to_read = 35_000_000\n",
    "\n",
    "df_ratings = pd.read_csv(movielens_data_dir + '/ratings.csv', nrows=num_ratings_to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwOzHRikpFxr",
    "outputId": "ecb25413-62c3-491f-9e9a-befb031d3b4d"
   },
   "outputs": [],
   "source": [
    "len(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuVToGGopH9z"
   },
   "outputs": [],
   "source": [
    "# clean the ratings data\n",
    "df_ratings = df_ratings.dropna()\n",
    "df_ratings['movieId'] = df_ratings['movieId'].astype(int, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QXNXWJio1oCB",
    "outputId": "d98aaf38-0584-496a-fa86-88f5e3d56fa8"
   },
   "outputs": [],
   "source": [
    "df_ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtiZsZrXpdAH"
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(movielens_data_dir + '/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "poniXr1fpg7R",
    "outputId": "c0415585-ec62-4265-818b-6861db1b0b2e"
   },
   "outputs": [],
   "source": [
    "df_movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZsEUjaTXtHV5"
   },
   "source": [
    "# Movie Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMJt7sFtAXmD",
    "outputId": "ab43ff72-cecc-436f-f5c6-c2fecf012825"
   },
   "outputs": [],
   "source": [
    "# let's only work with movies with enough ratings.\n",
    "\n",
    "min_ratings_per_movie = 4_000\n",
    "\n",
    "# get the number of ratings per movie\n",
    "df_movies_to_num_ratings = df_ratings.groupby('movieId', as_index=False)['rating'].count()\n",
    "print(\"total movies in corpus: \", len(df_movies_to_num_ratings))\n",
    "\n",
    "df_movies_to_num_ratings = df_movies_to_num_ratings.sort_values(by=['rating'], ascending=False)\n",
    "df_movies_to_num_ratings = df_movies_to_num_ratings[df_movies_to_num_ratings['rating'] > min_ratings_per_movie]\n",
    "print(\"movies with enough ratings: \", len(df_movies_to_num_ratings))\n",
    "\n",
    "# get list of the top movies by number of ratings.\n",
    "top_movies = df_movies_to_num_ratings.movieId.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTBR8snNEFvD"
   },
   "outputs": [],
   "source": [
    "# keep a map of movieId to number of ratings.\n",
    "movieId_to_num_ratings = {}\n",
    "movieId_list = df_movies_to_num_ratings.movieId.tolist()\n",
    "rating_list = df_movies_to_num_ratings.rating.tolist()\n",
    "for i in range(len(movieId_list)):\n",
    "  movieId_to_num_ratings[movieId_list[i]] = rating_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkXt5NOPqFqI"
   },
   "outputs": [],
   "source": [
    "# map movieId to title\n",
    "movieId_to_title = {}\n",
    "title_to_movieId = {}\n",
    "\n",
    "movieId_list = df_movies.movieId.tolist()\n",
    "title_list = df_movies.title.tolist()\n",
    "\n",
    "for i in range(len(movieId_list)):\n",
    "  movieId = movieId_list[i]\n",
    "  title = title_list[i]\n",
    "\n",
    "  movieId_to_title[movieId] = title\n",
    "  title_to_movieId[title] = movieId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_CQZfpeqYJ8",
    "outputId": "728347cc-0a2c-49a6-a28b-4c28c96f1b1a"
   },
   "outputs": [],
   "source": [
    "# print the top movies\n",
    "for movieId in top_movies[0:10]:\n",
    "  print(movieId, movieId_to_title[movieId], movieId_to_num_ratings[movieId])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-PkcA_pq67x"
   },
   "outputs": [],
   "source": [
    "# map movieId to list of genres for that movie\n",
    "genres = set()\n",
    "movieId_to_genres = {}\n",
    "\n",
    "movieId_list = df_movies.movieId.tolist()\n",
    "genre_list = df_movies.genres.tolist()\n",
    "\n",
    "for i in range(len(movieId_list)):\n",
    "  movieId = movieId_list[i]\n",
    "  if movieId not in top_movies:\n",
    "    continue\n",
    "\n",
    "  movieId_to_genres[movieId] = set()\n",
    "\n",
    "  for genre in genre_list[i].split('|'):\n",
    "    genres.add(genre)\n",
    "    movieId_to_genres[movieId].add(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5L0uRnlfrWAr",
    "outputId": "e9869df8-31ea-4828-db38-ff1a21c29239"
   },
   "outputs": [],
   "source": [
    "movieId_to_genres[title_to_movieId['Matrix, The (1999)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2erACCTmDWOk"
   },
   "outputs": [],
   "source": [
    "# for every movie, get the avg rating\n",
    "df_movies_to_avg_rating = df_ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "\n",
    "movieId_to_avg_rating = {}\n",
    "\n",
    "movieId_list = df_movies_to_avg_rating.movieId.tolist()\n",
    "rating_list = df_movies_to_avg_rating.rating.tolist()\n",
    "for i in range(len(movieId_list)):\n",
    "  if movieId_list[i] not in top_movies: continue\n",
    "  movieId_to_avg_rating[movieId_list[i]] = rating_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VlXL2NVrtag9"
   },
   "outputs": [],
   "source": [
    "# build ITEM movieId embedding mapping\n",
    "item_emb_movieId_to_i = {s:i for i,s in enumerate(top_movies)}\n",
    "item_emb_i_to_movieId = {i:s for s,i in item_emb_movieId_to_i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rs8YTabXtp0H"
   },
   "outputs": [],
   "source": [
    "# build ITEM genre feature context\n",
    "genre_to_i = {s:i for i,s in enumerate(genres)}\n",
    "i_to_genre = {i:s for s,i in genre_to_i.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiIp4GmVtKWR"
   },
   "source": [
    "# User Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyQWy0jylw1t"
   },
   "outputs": [],
   "source": [
    "# every user will have a feature context that will mostly be their watch history.\n",
    "# instead of using every movie in the corpus, we can use a smaller subset.\n",
    "# this helps with memory issues.\n",
    "num_movies_for_user_context = 500\n",
    "user_context_movies = top_movies[:num_movies_for_user_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJt4iYZGik-U"
   },
   "outputs": [],
   "source": [
    "df_ratings_final = df_ratings[df_ratings.movieId.isin(top_movies)]\n",
    "df_ratings_final = df_ratings_final.sort_values(['userId', 'timestamp'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tP8o3iQDTs7M"
   },
   "outputs": [],
   "source": [
    "# aggregate dataframe down into one row per user and list of their movies and ratings.\n",
    "df_ratings_final = df_ratings_final.groupby('userId').agg({'movieId': lambda x: list(x), 'rating': lambda y: list(y)}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "BFt2zuQCTuss",
    "outputId": "1615e932-275e-488a-9ac7-a3a6423bea54"
   },
   "outputs": [],
   "source": [
    "df_ratings_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUrl8Vzsu_h-"
   },
   "outputs": [],
   "source": [
    "# build the USER context\n",
    "user_context_size = len(user_context_movies) + len(genres)\n",
    "\n",
    "user_context_movieId_to_i = {s:i for i,s in enumerate(list(user_context_movies))}\n",
    "user_context_i_to_movieId = {i:s for s,i in user_context_movieId_to_i.items()}\n",
    "\n",
    "user_context_genre_avg_rating_to_i = {s:i+len(user_context_movies) for i,s in enumerate(list(genres))}\n",
    "user_context_i_to_genre_avg_rating = {i:s for s,i in user_context_genre_avg_rating_to_i.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fqs8Tf10v2qH"
   },
   "source": [
    "# Generate Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TfqvZbvESXz"
   },
   "outputs": [],
   "source": [
    "# simulate training examples by masking out some of the user's watched movies from their context, and using them as labels.\n",
    "# we do not want the 'movie to predict' in their watch history, as we are trying to simulate the following:\n",
    "# given the user's watch history, what would they rate this new movie?\n",
    "# NOTE: this is not the same as a train/test split. This is just simulating how training examples would look like on a movie platform.\n",
    "\n",
    "percent_ratings_as_watch_history = 0.9\n",
    "\n",
    "min_ratings_per_user = 20 # ignore users with too few movie watches\n",
    "max_ratings_per_user = 500 # ignore users with way too many movie watches\n",
    "too_few_ratings = 0\n",
    "too_many_ratings = 0\n",
    "\n",
    "user_to_movie_to_rating_WATCH_HISTORY = {}\n",
    "user_to_movie_to_rating_LABEL = {}\n",
    "\n",
    "# loop over each column as this is much, much faster than going row by row.\n",
    "user_list = df_ratings_final['userId'].tolist()\n",
    "movieId_list_list = df_ratings_final['movieId'].tolist()\n",
    "rating_list_list = df_ratings_final['rating'].tolist()\n",
    "\n",
    "for i in range(len(user_list)):\n",
    "  userId = user_list[i]\n",
    "  movieId_list = movieId_list_list[i]\n",
    "  rating_list = rating_list_list[i]\n",
    "\n",
    "  num_rated_movies = len(movieId_list)\n",
    "\n",
    "  # ignore users with too few or too many ratings.\n",
    "  if num_rated_movies < min_ratings_per_user:\n",
    "    too_few_ratings += 1\n",
    "    continue\n",
    "  if num_rated_movies > max_ratings_per_user:\n",
    "    too_many_ratings += 1\n",
    "    continue\n",
    "\n",
    "  # set up training example maps.\n",
    "  user_to_movie_to_rating_WATCH_HISTORY[userId] = {}\n",
    "  user_to_movie_to_rating_LABEL[userId] = {}\n",
    "\n",
    "  # shuffle the user's movies that they have watched\n",
    "  rated_movies = list(zip(movieId_list, rating_list))\n",
    "  # random.shuffle(rated_movies)\n",
    "\n",
    "  # put some movies into user's watch history (features) and leave others as labels to predict.\n",
    "  for movieId,rating in rated_movies[:int(num_rated_movies * percent_ratings_as_watch_history)]:\n",
    "    user_to_movie_to_rating_WATCH_HISTORY[userId][movieId] = rating\n",
    "  for movieId,rating in rated_movies[int(num_rated_movies * percent_ratings_as_watch_history):]:\n",
    "    user_to_movie_to_rating_LABEL[userId][movieId] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iy-5m8DhMaLT",
    "outputId": "86e13964-1ac5-4e28-bfbc-63b46c65c5bf"
   },
   "outputs": [],
   "source": [
    "len(user_list), len(user_to_movie_to_rating_WATCH_HISTORY.keys()), too_few_ratings, too_many_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOB_rm7Rxi_n"
   },
   "outputs": [],
   "source": [
    "# for every user, get their avg rating.\n",
    "# this will help us debias each user's rating.\n",
    "user_to_avg_rating = {}\n",
    "\n",
    "# NOTE: only use ratings from their synthetic watch history.\n",
    "for user in user_to_movie_to_rating_WATCH_HISTORY.keys():\n",
    "  user_to_avg_rating[user] = 0\n",
    "  for movieId in user_to_movie_to_rating_WATCH_HISTORY[user].keys():\n",
    "    user_to_avg_rating[user] += user_to_movie_to_rating_WATCH_HISTORY[user][movieId]\n",
    "\n",
    "  user_to_avg_rating[user] /= len(user_to_movie_to_rating_WATCH_HISTORY[user].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-9pIqURyEWU",
    "outputId": "12a9285f-3e5a-4080-a51d-b5ed9c699718"
   },
   "outputs": [],
   "source": [
    "user_to_avg_rating[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHc_u8YVyGUs"
   },
   "outputs": [],
   "source": [
    "# for every user, get the avg rating for every genre\n",
    "user_to_genre_to_stat = {}\n",
    "\n",
    "# NOTE: only use ratings from their synthetic watch history.\n",
    "for user in user_to_movie_to_rating_WATCH_HISTORY.keys():\n",
    "  user_to_genre_to_stat[user] = {}\n",
    "  for movieId in user_to_movie_to_rating_WATCH_HISTORY[user].keys():\n",
    "    for genre in movieId_to_genres[movieId]:\n",
    "      if genre not in user_to_genre_to_stat[user]:\n",
    "        user_to_genre_to_stat[user][genre] = {\n",
    "            'NUM_RATINGS': 0,\n",
    "            'SUM_RATINGS': 0,\n",
    "        }\n",
    "\n",
    "      user_to_genre_to_stat[user][genre]['NUM_RATINGS'] += 1\n",
    "      user_to_genre_to_stat[user][genre]['SUM_RATINGS'] += user_to_movie_to_rating_WATCH_HISTORY[user][movieId]\n",
    "\n",
    "for user in user_to_genre_to_stat.keys():\n",
    "  for genre in user_to_genre_to_stat[user].keys():\n",
    "    num_ratings = user_to_genre_to_stat[user][genre]['NUM_RATINGS']\n",
    "    sum_ratings = user_to_genre_to_stat[user][genre]['SUM_RATINGS']\n",
    "    user_to_genre_to_stat[user][genre]['AVG_RATING'] = sum_ratings / num_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "582v8d0Sy91s"
   },
   "outputs": [],
   "source": [
    "# for every user, create the training example user context vector\n",
    "# 0:num_user_context_movies -> user's watch history\n",
    "# num_user_context_movies:num_user_context_movies+num_genres -> user's genre avg rating\n",
    "# num_user_context_movies+num_genres:num_user_context_movies+num_genres+num_genres -> user's num movies watched in genre\n",
    "user_to_context = {}\n",
    "for user in user_to_movie_to_rating_WATCH_HISTORY.keys():\n",
    "  context = [0.0] * user_context_size\n",
    "\n",
    "  for movieId in user_to_movie_to_rating_WATCH_HISTORY[user].keys():\n",
    "    if movieId in user_context_movies:\n",
    "      # note, we debias the rating so if the rating is under the user's avg rating,\n",
    "      # it will hopefully count as negative strength for predicting similar movies.\n",
    "      # vice-versa for a rating above the user's average.\n",
    "      context[user_context_movieId_to_i[movieId]] = float(user_to_movie_to_rating_WATCH_HISTORY[user][movieId] - user_to_avg_rating[user])\n",
    "\n",
    "  for genre in user_to_genre_to_stat[user].keys():\n",
    "    # add the user's avg rating for this genre debiased using their actual avg rating from all movies\n",
    "    context[user_context_genre_avg_rating_to_i[genre]] = float(user_to_genre_to_stat[user][genre]['AVG_RATING'] - user_to_avg_rating[user])\n",
    "\n",
    "  user_to_context[user] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNLFC8wx0Gt2"
   },
   "outputs": [],
   "source": [
    "# for every movie, create a training example feature context vector lookup\n",
    "# it will contain the movie's genres.\n",
    "movieId_to_context = {}\n",
    "for movieId in top_movies:\n",
    "  context = [0.0] * len(genres)\n",
    "\n",
    "  for genre in movieId_to_genres[movieId]:\n",
    "    context[genre_to_i[genre]] = float(1.0)\n",
    "\n",
    "  movieId_to_context[movieId] = context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_lJar1sJE48"
   },
   "source": [
    "# Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeZR-nqC0nyt"
   },
   "outputs": [],
   "source": [
    "# Build the final Dataset\n",
    "def build_dataset(users):\n",
    "  # the user context (i.e. the watch hisotyr and genre affinities)\n",
    "  X = []\n",
    "\n",
    "  # the movieID for the movie we will predict rating for.\n",
    "  # used to lookup the movie embedding to feed into the NN item tower.\n",
    "  target_movieId = []\n",
    "\n",
    "  # the feature context of the movie we will predict the rating for.\n",
    "  # will also feed into it's own embedding and will be stacked with the embedding above.\n",
    "  target_movieId_context = []\n",
    "\n",
    "  # the predicted rating\n",
    "  Y = []\n",
    "\n",
    "  # create training examples, one for each movie the user has that we want as a label.\n",
    "  for user in users:\n",
    "    for movieId in user_to_movie_to_rating_LABEL[user].keys():\n",
    "      X.append(user_to_context[user])\n",
    "\n",
    "      target_movieId.append(item_emb_movieId_to_i[movieId])\n",
    "\n",
    "      target_movieId_context.append(movieId_to_context[movieId])\n",
    "\n",
    "      # remember to debias the user rating so we can learn to predict if user\n",
    "      # like/dislike a movie based on their features and the movie features.\n",
    "      Y.append(float(user_to_movie_to_rating_LABEL[user][movieId] - user_to_avg_rating[user]))\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  target_movieId = torch.tensor(target_movieId)\n",
    "  target_movieId_context = torch.tensor(target_movieId_context)\n",
    "\n",
    "  return X,Y,target_movieId,target_movieId_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UL41mDO2am8",
    "outputId": "35df6222-232a-4f76-fda5-4e290104c006"
   },
   "outputs": [],
   "source": [
    "# user users with enough ratings to predict to be useful for model learning.\n",
    "final_users = []\n",
    "\n",
    "for user in user_to_movie_to_rating_LABEL.keys():\n",
    "  num_ratings = len(user_to_movie_to_rating_LABEL[user])\n",
    "\n",
    "  if num_ratings >= 5 and num_ratings < 500:\n",
    "    final_users.append(user)\n",
    "\n",
    "len(final_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NH7iFOJULzi7"
   },
   "outputs": [],
   "source": [
    "# split users into train and validation users\n",
    "percent_users_train = 0.9\n",
    "\n",
    "random.shuffle(final_users)\n",
    "\n",
    "train_users = final_users[:int(len(final_users) * percent_users_train)]\n",
    "validation_users = final_users[int(len(final_users) * percent_users_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOf31QdW2pIW"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, target_movieId_train, target_movieId_context_train = build_dataset(train_users)\n",
    "X_val, Y_val, target_movieId_val, target_movieId_context_val = build_dataset(validation_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUtSY4e32uLo",
    "outputId": "a4baa290-3e5c-498b-a5cd-f8c0e52083cc"
   },
   "outputs": [],
   "source": [
    "print(\"train: \", X_train.shape, Y_train.shape, target_movieId_train.shape, target_movieId_context_train.shape)\n",
    "print(\"val: \", X_val.shape, Y_val.shape, target_movieId_val.shape, target_movieId_context_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nE_-j5B3WVM"
   },
   "source": [
    "# Build our Two Tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "user_features ---------------> u_W1\n",
    "                                    \\\n",
    "                                     \\\n",
    "                                      --> dot_product(user, item) --> prediction\n",
    "                                     /\n",
    "movie_features  -> i_W1             /\n",
    "                        \\          /\n",
    "                         --> stack\n",
    "                        /\n",
    "movie_embedding -> e_W1\n",
    "'''\n",
    "\n",
    "class MovieRecommender(nn.Module):\n",
    "    def __init__(self, genres_len, top_movies_len, user_context_size,\n",
    "                 item_feature_embedding_size=10,\n",
    "                 item_movieId_embedding_size=40,\n",
    "                 user_feature_embedding_size=50\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initializes the MovieRecommender model.\n",
    "\n",
    "        Args:\n",
    "            genres_len (int): Number of unique genres (dimension of movie genre features).\n",
    "            top_movies_len (int): Total number of unique movie IDs in the lookup table.\n",
    "            user_context_size (int): Dimension of user context features.\n",
    "            item_feature_embedding_size (int): Desired embedding size for item genre features.\n",
    "            item_movieId_embedding_size (int): Desired embedding size for movie IDs.\n",
    "            user_feature_embedding_size (int): Desired embedding size for user features.\n",
    "                                               This must match the combined item embedding size.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.item_feature_tower = nn.Sequential(\n",
    "            nn.Linear(genres_len, item_feature_embedding_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.item_embedding_lookup = nn.Embedding(top_movies_len, item_movieId_embedding_size)\n",
    "        self.item_embedding_tower = nn.Sequential(\n",
    "            nn.Linear(item_movieId_embedding_size, item_movieId_embedding_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.user_feature_tower = nn.Sequential(\n",
    "            nn.Linear(user_context_size, user_feature_embedding_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Dimension check: The user embedding size must match the combined item embedding size\n",
    "        # for the dot product to be valid.\n",
    "        expected_combined_item_embedding_size = item_feature_embedding_size + item_movieId_embedding_size\n",
    "        if user_feature_embedding_size != expected_combined_item_embedding_size:\n",
    "            raise ValueError(\n",
    "                f\"User embedding size ({user_feature_embedding_size}) must match \"\n",
    "                f\"combined item embedding size ({expected_combined_item_embedding_size}) \"\n",
    "                f\"for the dot product operation. Please adjust `user_feature_embedding_size`.\"\n",
    "            )\n",
    "\n",
    "        # Apply custom weight initialization to all applicable layers\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        Applies a small scale to initial weights for Linear and Embedding layers.\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # Using Xavier uniform initialization which is good for Tanh activation\n",
    "            # The gain parameter scales the initialization.\n",
    "            torch.nn.init.xavier_uniform_(module.weight, gain=0.01)\n",
    "            if module.bias is not None:\n",
    "                # Initialize biases to zero\n",
    "                torch.nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            # For embedding layers, also use Xavier uniform initialization\n",
    "            torch.nn.init.xavier_uniform_(module.weight, gain=0.01)\n",
    "\n",
    "    def forward(self, user_contexts, movie_contexts, target_movieId):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_contexts (torch.Tensor): Batch of user context features.\n",
    "                                          Shape: (batch_size, user_context_size)\n",
    "            movie_contexts (torch.Tensor): Batch of target movie genre features.\n",
    "                                           Shape: (batch_size, genres_len)\n",
    "            target_movieId (torch.Tensor): Batch of target movie ID indices.\n",
    "                                           Shape: (batch_size,)\n",
    "        \"\"\"\n",
    "        # Forward pass through the USER tower\n",
    "        user_embedding = self.user_feature_tower(user_contexts) # Shape: (batch_size, user_feature_embedding_size)\n",
    "\n",
    "        # Forward pass through the ITEM movie feature tower\n",
    "        item_feature_embedding = self.item_feature_tower(movie_contexts) # Shape: (batch_size, item_feature_embedding_size)\n",
    "\n",
    "        # Lookup the ITEM movieId embedding and pass through its non-linear layer\n",
    "        item_embedding_hidden = self.item_embedding_tower(self.item_embedding_lookup(target_movieId)) # Shape: (batch_size, item_movieId_embedding_size)\n",
    "\n",
    "        # Concatenate the two ITEM embeddings together\n",
    "        # `torch.cat` combines tensors along a given dimension.\n",
    "        # `dim=1` means concatenate along the feature dimension for each sample in the batch.\n",
    "        item_embedding_combined = torch.cat((item_feature_embedding, item_embedding_hidden), dim=1)\n",
    "        # Resulting shape: (batch_size, item_feature_embedding_size + item_movieId_embedding_size)\n",
    "\n",
    "        # The final prediction is the dot product of the user embedding and the combined item embedding.\n",
    "        # `torch.einsum('ij, ij -> i', A, B)` performs element-wise multiplication\n",
    "        # and then sums along the 'j' dimension for each 'i'.\n",
    "        # This is equivalent to `(user_embedding * item_embedding_combined).sum(dim=1)`.\n",
    "        preds = torch.einsum('ij, ij -> i', user_embedding, item_embedding_combined)\n",
    "\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lNS2VzCbw_8"
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "\n",
    "# Define model hyper-parameters\n",
    "item_feature_embedding_size = 10\n",
    "item_movieId_embedding_size = 40\n",
    "\n",
    "# User embedding size must match the sum of item_feature_embedding_size and item_movieId_embedding_size\n",
    "user_feature_embedding_size = item_feature_embedding_size + item_movieId_embedding_size\n",
    "\n",
    "# Instantiate the MovieRecommender model\n",
    "model = MovieRecommender(\n",
    "    genres_len=len(genres),\n",
    "    top_movies_len=len(top_movies),\n",
    "    user_context_size=user_context_size,\n",
    "    item_feature_embedding_size=item_feature_embedding_size,\n",
    "    item_movieId_embedding_size=item_movieId_embedding_size,\n",
    "    user_feature_embedding_size=user_feature_embedding_size\n",
    ")\n",
    "\n",
    "# Print the total number of trainable parameters in the model\n",
    "print(f\"Number of trainable parameters: {sum(p.nelement() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "# Set the loss function (Mean Squared Error Loss for regression)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Set the optimizer (Stochastic Gradient Descent)\n",
    "# It will manage the updates to all parameters in `model.parameters()`\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training configuration\n",
    "minibatch_size = 64\n",
    "loss_train = [] # To store training loss for each step\n",
    "loss_val = []   # To store validation loss for full validation runs\n",
    "\n",
    "log_every = 10_000       # How often to perform a full validation run and log\n",
    "training_steps = 100_000 # Total training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStarting training loop...\")\n",
    "\n",
    "for i in range(training_steps):\n",
    "    is_full_val_run = False\n",
    "    if i % log_every == 0:\n",
    "        is_full_val_run = True\n",
    "\n",
    "    # Select data for the current step (training minibatch or full validation set)\n",
    "    if is_full_val_run:\n",
    "        # Use full validation set for evaluation\n",
    "        user_contexts_batch = X_val\n",
    "        movie_contexts_batch = target_movieId_context_val\n",
    "        target_movieId_batch = target_movieId_val\n",
    "        Y_batch = Y_val\n",
    "        model.eval() # Set model to evaluation mode (e.g., disables dropout if present)\n",
    "        with torch.no_grad(): # Disable gradient calculations for validation\n",
    "            preds = model(user_contexts_batch, movie_contexts_batch, target_movieId_batch)\n",
    "            output = loss_fn(preds, Y_batch)\n",
    "        loss_val.append(output.item()) # Store validation loss\n",
    "    else:\n",
    "        # Construct a random minibatch from training data\n",
    "        ix = torch.randint(0, X_train.shape[0], (minibatch_size,))\n",
    "        user_contexts_batch = X_train[ix]\n",
    "        movie_contexts_batch = target_movieId_context_train[ix]\n",
    "        target_movieId_batch = target_movieId_train[ix]\n",
    "        Y_batch = Y_train[ix]\n",
    "        model.train() # Set model to training mode (e.g., enables dropout)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(user_contexts_batch, movie_contexts_batch, target_movieId_batch)\n",
    "        output = loss_fn(preds, Y_batch)\n",
    "        loss_train.append(output.item()) # Store training loss for this batch\n",
    "\n",
    "        # Backpropagation and update weights\n",
    "        optimizer.zero_grad() # Clear gradients from the previous step\n",
    "        output.backward()     # Compute gradients for all parameters\n",
    "        optimizer.step()      # Update model parameters using the computed gradients\n",
    "\n",
    "    # Logging\n",
    "    if is_full_val_run:\n",
    "        # Calculate average training loss over the last `log_every` batches\n",
    "        if i >= log_every:\n",
    "            avg_train_loss_last_batches = np.mean(loss_train[i-log_every:i])\n",
    "        else:\n",
    "            # If not enough training batches collected yet, use the current validation loss\n",
    "            # (or you could skip logging train loss for the very first validation run)\n",
    "            avg_train_loss_last_batches = output.item()\n",
    "        print(f\"[TRAIN] i: {i:06d} | avg_loss (last {log_every} batches): {avg_train_loss_last_batches:.4f}\")\n",
    "        print(f\"[VAL]   i: {i:06d} | loss: {output.item():.4f}\\n\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "P8xcagsxeZf_",
    "outputId": "947332e3-e17e-4d7a-a31f-ce17c5250534"
   },
   "outputs": [],
   "source": [
    "loss_train_bucket_means = []\n",
    "for i in range(0, len(loss_train), log_every):\n",
    "  loss_train_bucket_means.append(np.mean(loss_train[i:i+log_every]))\n",
    "\n",
    "plt.plot([i*1000 for i in range(len(loss_train_bucket_means))], loss_train_bucket_means)\n",
    "plt.plot([i*1000 for i in range(1, len(loss_val))], loss_val[1:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F1xNlzXe4gi"
   },
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'saved_models/20250530.pth'\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F1xNlzXe4gi"
   },
   "source": [
    "# Actually Using the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovieRecommender(\n",
    "    genres_len=len(genres),\n",
    "    top_movies_len=len(top_movies),\n",
    "    user_context_size=user_context_size\n",
    ")\n",
    "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJsFMEk8e6SZ"
   },
   "outputs": [],
   "source": [
    "# for every movie, save all its embeddings\n",
    "movieId_to_embedding = {}\n",
    "\n",
    "ITEM_EMBEDDING_LOOKUP = model.item_embedding_lookup.weight\n",
    "\n",
    "for movieId in top_movies:\n",
    "  movieId_to_embedding[movieId] = {}\n",
    "\n",
    "  item_embedding = ITEM_EMBEDDING_LOOKUP[torch.tensor([item_emb_movieId_to_i[movieId]])]\n",
    "\n",
    "  movieId_to_embedding[movieId]['MOVIEID_EMBEDDING'] = model.item_embedding_tower(item_embedding)\n",
    "\n",
    "  movieId_to_embedding[movieId]['MOVIE_FEATURE_EMBEDDING'] = model.item_feature_tower(torch.tensor([movieId_to_context[movieId]]))\n",
    "\n",
    "  # compute the combined (concat) item/movie embedding\n",
    "  item_id_emb = movieId_to_embedding[movieId]['MOVIEID_EMBEDDING']\n",
    "  item_feature_emb = movieId_to_embedding[movieId]['MOVIE_FEATURE_EMBEDDING']\n",
    "  movieId_to_embedding[movieId]['MOVIE_EMBEDDING_COMBINED'] = torch.cat((item_feature_emb, item_id_emb), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVd99qEGfOwh",
    "outputId": "6f647549-05fd-4dca-c3a6-438bf45a5e47"
   },
   "outputs": [],
   "source": [
    "for emb_type in movieId_to_embedding[5952].keys():\n",
    "  print(movieId_to_embedding[5952][emb_type].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAxhh6sRyEDY"
   },
   "source": [
    "### Viewing Movies in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6z8ccMyyGTi"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for movieId in top_movies[0:25]:\n",
    "  i = item_emb_movieId_to_i[movieId]\n",
    "  plt.scatter(ITEM_EMBEDDING_LOOKUP[i,0].data, ITEM_EMBEDDING_LOOKUP[i,1].data, s=200)\n",
    "  plt.text(ITEM_EMBEDDING_LOOKUP[i,0].item(), ITEM_EMBEDDING_LOOKUP[i,1].item(), movieId_to_title[movieId][0:20], ha=\"center\", va=\"center\", color='black')\n",
    "plt.grid('minor')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDjCGr5Lhu-K"
   },
   "source": [
    "### Finding Most Similar Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tbu2Y9rggFaY"
   },
   "outputs": [],
   "source": [
    "# for every movie, and for every embedding type, find the similary to all other embeddings\n",
    "# NOTE: can be slow\n",
    "movieId_to_emb_type_to_similarities = {}\n",
    "\n",
    "for movieId in top_movies:\n",
    "  movieId_to_emb_type_to_similarities[movieId] = {}\n",
    "\n",
    "  # for emb_type in movieId_to_embedding[movieId].keys():\n",
    "  for emb_type in ['MOVIE_EMBEDDING_COMBINED']:\n",
    "    emb_to_target_to_dist = {}\n",
    "    for target_id in top_movies:\n",
    "      src = movieId_to_embedding[movieId][emb_type].view(-1)\n",
    "      target = movieId_to_embedding[target_id][emb_type].view(-1)\n",
    "\n",
    "      distance = torch.sqrt(torch.sum(torch.pow(torch.subtract(src, target), 2), dim=0))\n",
    "      emb_to_target_to_dist[target_id] = distance.item()\n",
    "    movieId_to_emb_type_to_similarities[movieId][emb_type] = list(sorted(emb_to_target_to_dist.items(), key=lambda item: item[1]))[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpPb5tqphOB-"
   },
   "outputs": [],
   "source": [
    "titles = [\n",
    "    'Lord of the Rings: The Return of the King, The (2003)',\n",
    "    'Star Wars: Episode IV - A New Hope (1977)',\n",
    "    'Toy Story (1995)',\n",
    "    'Saving Private Ryan (1998)',\n",
    "    'Kill Bill: Vol. 1 (2003)',\n",
    "    'American Pie (1999)',\n",
    "    'Blair Witch Project, The (1999)',\n",
    "    'Princess Mononoke (Mononoke-hime) (1997)'\n",
    "]\n",
    "\n",
    "emb_type = 'MOVIE_EMBEDDING_COMBINED'\n",
    "\n",
    "table = '| Movie |'\n",
    "for i in range(5):\n",
    "  table += ' Similar {} |'.format(i+1)\n",
    "table += '\\n'\n",
    "for i in range(5):\n",
    "  table += '|-----'\n",
    "table += '|\\n'\n",
    "\n",
    "# Print the top most similar movies\n",
    "for title in titles:\n",
    "  movieId = title_to_movieId[title]\n",
    "\n",
    "  table += '| '\n",
    "  for target_id, dist in movieId_to_emb_type_to_similarities[movieId][emb_type][0:5+1]:\n",
    "    table += movieId_to_title[target_id] + ' | '\n",
    "  table += '\\n'\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDjCGr5Lhu-K"
   },
   "source": [
    "### Get Recommendations for Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TG4oRn7ztTNe"
   },
   "outputs": [],
   "source": [
    "for movieId in user_context_movies:\n",
    "    print(movieId_to_title[movieId], movieId_to_genres[movieId])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukMIw_w0iLy_"
   },
   "outputs": [],
   "source": [
    "user_type_to_favorite_genres = {\n",
    "    'Fantasy Lover': ['Fantasy'],\n",
    "    'Children\\'s Movie Lover': ['Children'],\n",
    "    'Horror Lover': ['Horror'],\n",
    "    'Sci-Fi Lover': ['Sci-Fi'],\n",
    "    'Comedy Lover': ['Comedy'],\n",
    "    'Romance Lover': ['Romance'],\n",
    "    'War Movie Lover': ['War'],\n",
    "    'Martial Arts Lover': ['Action'],\n",
    "\n",
    "    # profile for myself\n",
    "    'Myself': ['Fantasy', 'War', 'Horror', 'Drama', 'Action']\n",
    "}\n",
    "\n",
    "user_type_to_worst_genres = {\n",
    "    'Fantasy Lover': ['Horror', 'Children'],\n",
    "    'Children\\'s Movie Lover': ['Horror', 'Romance', 'Drama'],\n",
    "    'Horror Lover': ['Children'],\n",
    "    'Sci-Fi Lover': ['Romance', 'Children'],\n",
    "    'Comedy Lover': ['Children'],\n",
    "    'Romance Lover': ['Children', 'Horror'],\n",
    "    'War Movie Lover': ['Children'],\n",
    "    'Martial Arts Lover': ['Children', 'Romance', 'Drama', 'Horror'],\n",
    "    \n",
    "    # profile for myself\n",
    "    'Myself': ['Romance']\n",
    "}\n",
    "\n",
    "user_type_to_favorite_movies = {\n",
    "    'Fantasy Lover': [\n",
    "        'Lord of the Rings: The Fellowship of the Ring, The (2001)',\n",
    "        'Lord of the Rings: The Two Towers, The (2002)',\n",
    "        'Gladiator (2000)',\n",
    "        '300 (2007)',\n",
    "        'Braveheart (1995)'\n",
    "        ],\n",
    "    'Children\\'s Movie Lover': [\n",
    "        'Toy Story 2 (1999)',\n",
    "        'Finding Nemo (2003)',\n",
    "        'Monsters, Inc. (2001)'\n",
    "        ],\n",
    "    'Horror Lover': [\n",
    "        'Blair Witch Project, The (1999)',\n",
    "        'Silence of the Lambs, The (1991)',\n",
    "        'Sixth Sense, The (1999)'\n",
    "        ],\n",
    "    'Sci-Fi Lover': [\n",
    "        'Star Wars: Episode V - The Empire Strikes Back (1980)',\n",
    "        'Matrix, The (1999)',\n",
    "        'Terminator, The (1984)'\n",
    "        ],\n",
    "    'Comedy Lover': [\n",
    "        'American Pie (1999)',\n",
    "        'Dumb & Dumber (Dumb and Dumber) (1994)',\n",
    "        'Austin Powers: The Spy Who Shagged Me (1999)',\n",
    "        'Big Lebowski, The (1998)'\n",
    "      ],\n",
    "    'Romance Lover': [\n",
    "        'Shakespeare in Love (1998)',\n",
    "        'There\\'s Something About Mary (1998)',\n",
    "        'Sense and Sensibility (1995)'\n",
    "    ],\n",
    "    'War Movie Lover': [\n",
    "        'Saving Private Ryan (1998)',\n",
    "        'Apocalypse Now (1979)',\n",
    "        'Full Metal Jacket (1987)'\n",
    "    ],\n",
    "    'Martial Arts Lover': [\n",
    "        'Kill Bill: Vol. 2 (2004)',\n",
    "        'Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)',\n",
    "        'Last Samurai, The (2003)',\n",
    "        'Seven Samurai (Shichinin no samurai) (1954)',\n",
    "    ],\n",
    "    \n",
    "    # profile for myself\n",
    "    'Myself': [\n",
    "        'Lord of the Rings: The Fellowship of the Ring, The (2001)',\n",
    "        'Lord of the Rings: The Two Towers, The (2002)',\n",
    "        'Lord of the Rings: The Return of the King, The (2003)',\n",
    "        '300 (2007)',\n",
    "        'Saving Private Ryan (1998)',\n",
    "        'Kill Bill: Vol. 1 (2003)',\n",
    "        '28 Days Later (2002)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "value_for_favorite_genre_avg_rating = float(5.0)\n",
    "value_for_disliked_genre_avg_rating = float(-2.0)\n",
    "value_for_favorite_movie_rating = float(2.0)\n",
    "\n",
    "user_to_inference_context = {}\n",
    "\n",
    "for user_type in user_type_to_favorite_genres.keys():\n",
    "  inference_user_context = [0.0] * user_context_size\n",
    "\n",
    "  # set genres the user likes (avg rating + ratio)\n",
    "  for genre in user_type_to_favorite_genres[user_type]:\n",
    "    inference_user_context[user_context_genre_avg_rating_to_i[genre]] = value_for_favorite_genre_avg_rating\n",
    "\n",
    "  # set genres that the user dislikes (avg rating)\n",
    "  for genre in user_type_to_worst_genres[user_type]:\n",
    "    inference_user_context[user_context_genre_avg_rating_to_i[genre]] = value_for_disliked_genre_avg_rating\n",
    "\n",
    "  # set the user's favorite movies.\n",
    "  for title in user_type_to_favorite_movies[user_type]:\n",
    "    movieId = title_to_movieId[title]\n",
    "    inference_user_context[user_context_movieId_to_i[movieId]] = value_for_favorite_movie_rating\n",
    "\n",
    "  user_to_inference_context[user_type] = inference_user_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzX6zAt7Wgqx"
   },
   "outputs": [],
   "source": [
    "user_to_top_recs = {}\n",
    "\n",
    "for user_type in user_to_inference_context.keys():\n",
    "\n",
    "  X_inference = torch.tensor([user_to_inference_context[user_type]])\n",
    "  user_embedding_inference = model.user_feature_tower(X_inference)\n",
    "\n",
    "  movieId_to_pred_score = {}\n",
    "  for movieId in top_movies:\n",
    "    # we already have the combined item embedding for every movie to make inference easier.\n",
    "    item_embedding_combined_inference = movieId_to_embedding[movieId]['MOVIE_EMBEDDING_COMBINED']\n",
    "    preds = torch.einsum('ij, ij -> i', user_embedding_inference, item_embedding_combined_inference)\n",
    "    movieId_to_pred_score[movieId] = preds\n",
    "\n",
    "  top_recs = []\n",
    "  show_top_recs = True\n",
    "  for movieId, pred_score in list(sorted(movieId_to_pred_score.items(), key=lambda item: item[1], reverse=show_top_recs)):\n",
    "    if len(top_recs) >= 10: break\n",
    "    if movieId_to_title[movieId] not in user_type_to_favorite_movies[user_type]:\n",
    "      top_recs.append(movieId)\n",
    "  user_to_top_recs[user_type] = top_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxtcVRHzGucO",
    "outputId": "a288f48c-7049-4954-8bd0-883b4992df24"
   },
   "outputs": [],
   "source": [
    "for user_type in user_to_top_recs.keys():\n",
    "  print(\"Hello, \" + user_type)\n",
    "  print(\"Because you like: [\" + ','.join(user_type_to_favorite_genres[user_type]) + ']')\n",
    "  print(\"And hate: [\" + ','.join(user_type_to_worst_genres[user_type]) + ']')\n",
    "  print(\"And enjoyed these movies:\")\n",
    "  for title in user_type_to_favorite_movies[user_type]:\n",
    "    print(title)\n",
    "  print()\n",
    "\n",
    "  print(\"You should watch:\")\n",
    "  for movieId in user_to_top_recs[user_type]:\n",
    "    print(movieId_to_title[movieId])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_IgQlt4kEPp"
   },
   "outputs": [],
   "source": [
    "# sanity check - make sure we aren't just recommending the higest rated movies\n",
    "# NOTE: this is an extremely common problem in rec systems as the model learns\n",
    "# to play it safe and just recommend what almost is highly rated.\n",
    "for movieId, avg_rating in sorted(movieId_to_avg_rating.items(), key=lambda item: item[1], reverse=True)[0:10]:\n",
    "  print(movieId_to_title[movieId], avg_rating)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
